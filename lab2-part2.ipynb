{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Μέρος 2: Εντοπισμός Χωρο-χρονικών Σημείων Ενδιαφέροντος και Εξαγωγή Χαρακτηριστικών σε Βίντεο Ανθρωπίνων Δράσεων"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Βλάχος Ιωάννης, 03115013, 10ο, εξάμηνο, ΣΗΜΜΥ, ΕΜΠ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ακαδημαϊκό Έτός 2019-2020, εαρινό εξάμηνο"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Χωρο-χρονικά Σημεία Ενδιαφέροντος\n",
    "\n",
    "Συμπεριλαμβάνουμε τις απαραίτητες βιβλιοθήκες για την εκτέλεση των πειραμάτων."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "from scipy.ndimage import convolve, convolve1d\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Κατασκευάζουμε τον διδιάστατο και τρισδιάστατο γκαουσιανό πυρήνα που θα μας χρειαστούν στη συνέχεια για το φιλτράρισμα της ακολουθίας εικόνων. Ο διδιάστατος κατασκευάζεται με πολλαπλασιασμό μονοδιάστατων πυρήνων ενώ ο τρισδιάστος με ένα ακόμα εξωτερικό γινόμενο το οποίο κανουμε reshape. Η τρίτη διάσταση είναι ο χρόνος και μπορεί να έχει διαφορετική διάσταση από τις άλλες 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 19, 13)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gaussian_kernel(std):\n",
    "    siz = int(2*np.ceil(3*std)+1)\n",
    "    x = cv2.getGaussianKernel(siz, std)\n",
    "    return np.multiply(x.T, x)\n",
    "\n",
    "def gauss3d(std, r):\n",
    "    sizs = int(2*np.ceil(3*std)+1)\n",
    "    sizr = int(2*np.ceil(3*r)+1)\n",
    "    x = cv2.getGaussianKernel(sizs, std).flatten()\n",
    "    y = cv2.getGaussianKernel(sizr, r).flatten()\n",
    "    xx = np.outer(x, x)\n",
    "    return np.outer(xx,y).reshape((x.shape[0], x.shape[0], y.shape[0]))\n",
    "\n",
    "a = gauss3d(3, 2)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Περιλαμβάνουμε και τις συναρτήσεις της πρώτης εργαστηριακής άσκησης για να ελέγξουμε την λειτουργία του ανιχνευτή γωνίων Harris-Stephens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interest_points_visualization(I_, kp_data_, ax=None):\n",
    "    '''\n",
    "    Plot keypoints chosen by detectos on image.\n",
    "    Args:\n",
    "        I_: Image (if colored, make sure it is in RGB and not BGR).\n",
    "        kp_data_: Nx3 array, as described in assignment.\n",
    "        ax: Matplotlib axis to plot on (if None, a new Axes object is created).\n",
    "    Returns:\n",
    "        ax: Matplotlib axis where the image was plotted.\n",
    "    '''\n",
    "    try:\n",
    "        I = np.array(I_)\n",
    "        kp_data = np.array(kp_data_)\n",
    "    except:\n",
    "        print('Conversion to numpy arrays failed, check if the inputs (image and keypoints) are in the required format.')\n",
    "        exit(2)\n",
    "\n",
    "    try:\n",
    "        assert(len(I.shape) == 2 or (len(I.shape) == 3 and I.shape[2] == 3))\n",
    "    except AssertionError as e:\n",
    "        print('interest_points_visualization: Image must be either a 2D matrix or a 3D matrix with the last dimension having size equal to 3.', file=sys.stderr)\n",
    "        exit(2)\n",
    "\n",
    "    try:\n",
    "        assert(len(kp_data.shape) == 2 and kp_data.shape[1] == 3)\n",
    "    except AssertionError as e:\n",
    "        print('interest_points_visualization: kp_data must be a 2D matrix with 3 columns.', file=sys.stderr)\n",
    "        exit(2)\n",
    "\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "\n",
    "    ax.set_aspect('equal')\n",
    "    ax.imshow(I)\n",
    "    ax.tick_params(bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "\n",
    "    for i in range(len(kp_data)):\n",
    "        x, y, sigma = kp_data[i]\n",
    "        circ = Circle((x, y), 3*sigma, edgecolor='g', fill=False, linewidth=2)\n",
    "        ax.add_patch(circ)\n",
    "\n",
    "    return ax\n",
    "\n",
    "def disk_strel(n):\n",
    "    '''\n",
    "        Return a structural element, which is a disk of radius n.\n",
    "    '''\n",
    "    r = int(np.round(n))\n",
    "    d = 2*r+1\n",
    "    x = np.arange(d) - r\n",
    "    y = np.arange(d) - r\n",
    "    x, y = np.meshgrid(x,y)\n",
    "    strel = x**2 + y**2 <= r**2\n",
    "    return strel.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Διαβάζουμε 200 frames από το βίντεο."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 160, 200)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cv20_lab2_2_utils import read_video\n",
    "from cv20_lab2_2_utils import show_detection\n",
    "\n",
    "a = read_video('./running/person01_running_d1_uncomp.avi', 200, 0)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.1\n",
    "\n",
    "Παρακάτω υλοποιείται ο τροποποιημένος Harris Stephens ανιχνευτής γωνιών για αλληλουχία εικόνων.\n",
    "Για τον υπολογισμό των παραγώγων εκτελούμε convolve1d αλλά κατά μήκος του άξονα κατά τον οποίο θέλουμε να παραγωγίσουμε.\n",
    "Αφού υπολογίσουμε από αυτές τις παραγώγους τα 9 στοιχεία του πίνακα Μ, εκτελούμε στην τελική συνέλιξη με τον τρισδιάστατο γκαουσιανό εκτελώντας πάλι convolve 1d σε κάθε μία από τις 3 διαστάσεις του πίνακα Μ. Τέλος βρίσκουμε τον πίνακα Η σύμφωνα με την εξίσωση της εκφώνησης της άσκησης. Επιλέγουμε τα στοιχεία με τις μεγαλύτερες τιμές και τα δίνουμε σε κατάλληλη μορφή για να δοθεί ως όρισμα στην show detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HarrisStephens(img, sigma=2.5, r = 1.5, s=2, k=0.007, points=1000):\n",
    "    sizs = int(2*np.ceil(3*s*sigma)+1)\n",
    "    sizr = int(2*np.ceil(3*s*r)+1)\n",
    "    '''\n",
    "    G = gauss3d(s*sigma, s*r)\n",
    "    G = np.expand_dims(np.expand_dims(G, axis=-1), -1)\n",
    "    '''\n",
    "    ker=np.array([-1,0,1])\n",
    "\n",
    "    Lx = convolve1d(img, weights=ker, axis=0)\n",
    "    Ly = convolve1d(img, weights=ker, axis=1)\n",
    "    Lt = convolve1d(img, weights=ker, axis=2)\n",
    "    \n",
    "    Lxx = Lx*Lx\n",
    "    Lyy = Ly*Ly\n",
    "    Ltt = Lt*Lt\n",
    "    \n",
    "    Lxy = Lx*Ly\n",
    "    Lxt = Lx*Lt\n",
    "    Lyt = Ly*Lt\n",
    "    \n",
    "    Ms = np.zeros(img.shape+(3,3))\n",
    "    \n",
    "    Ms[:,:,:,0,0] = Lxx\n",
    "    Ms[:,:,:,0,1] = Lxy\n",
    "    Ms[:,:,:,0,2] = Lxt\n",
    "    Ms[:,:,:,1,0] = Lxy\n",
    "    Ms[:,:,:,1,1] = Lyy\n",
    "    Ms[:,:,:,1,2] = Lyt\n",
    "    Ms[:,:,:,2,0] = Lxt\n",
    "    Ms[:,:,:,2,1] = Lyt\n",
    "    Ms[:,:,:,2,2] = Ltt\n",
    "    \n",
    "    #M = convolve(Ms, G)\n",
    "    M=convolve1d(Ms,weights=cv2.getGaussianKernel(sizs, sigma*s).flatten(), axis=0)\n",
    "    M=convolve1d(M,weights=cv2.getGaussianKernel(sizs, sigma*s).flatten(), axis=1)\n",
    "    M=convolve1d(M,weights=cv2.getGaussianKernel(sizr, r*s).flatten(), axis=-1)\n",
    "    \n",
    "    H = np.linalg.det(M[:,:,:]) - k*np.trace(M, axis1=-2, axis2=-1)\n",
    "    ss = np.full((points),sigma)\n",
    "    p = np.unravel_index(np.argsort(H, axis=None), H.shape)\n",
    "    detect = np.zeros((4, points))\n",
    "    detect[0]=p[0][-points:]\n",
    "    detect[1]=p[1][-points:]\n",
    "    detect[2]=p[2][-points:]\n",
    "    detect[3]=ss\n",
    "    #plt.imshow(H[:,:,10])\n",
    "    #return H, detect.T\n",
    "    return detect.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Για τις 3 κατηγορίες βίντεο καλούμε την παραπάνω συνάρτηση και σώζουμε τα αποτελέσματα."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#H, inp = HarrisStephens(a, sigma=3, r=1.5, s=2, k=0.005, points=500)\n",
    "inp = HarrisStephens(a, sigma=3, r=1.5, s=2, k=0.005, points=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(H[:,:,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_detection(a, inp, save_path=\"C:\\\\Users\\\\ΓΙΑΝΝΗΣ\\\\Desktop\\\\οραση\\\\lab2\\\\cv20_lab2_part2_material\\\\part2-videos\\\\Harris_running\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = read_video('./walking/person04_walking_d1_uncomp.avi', 200, 0)\n",
    "inp = HarrisStephens(a, sigma=3, r=1.5, s=2, k=0.005, points=500)\n",
    "show_detection(a, inp, save_path=\"C:\\\\Users\\\\ΓΙΑΝΝΗΣ\\\\Desktop\\\\οραση\\\\lab2\\\\cv20_lab2_part2_material\\\\part2-videos\\\\Harris_walking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = read_video('./boxing/person01_boxing_d2_uncomp.avi', 200, 0)\n",
    "inp = HarrisStephens(a, sigma=3, r=1.5, s=2, k=0.005, points=500)\n",
    "show_detection(a, inp, save_path=\"C:\\\\Users\\\\ΓΙΑΝΝΗΣ\\\\Desktop\\\\οραση\\\\lab2\\\\cv20_lab2_part2_material\\\\part2-videos\\\\Harris_boxing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.53123856, 0.49533034],\n",
       "        [0.45191158, 0.12644268]],\n",
       "\n",
       "       [[0.35815544, 0.23486168],\n",
       "        [0.88613236, 0.16787317]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.random.rand(2,2,2)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 1, 1, 0, 0, 0, 1], dtype=int64),\n",
       " array([1, 1, 0, 0, 1, 0, 0, 1], dtype=int64),\n",
       " array([1, 1, 1, 0, 0, 1, 0, 0], dtype=int64))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unravel_index(np.argsort(b, axis=None), b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 19)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gauss2d(std):\n",
    "    sizs = int(2*np.ceil(3*std)+1)\n",
    "    x = cv2.getGaussianKernel(sizs, std).flatten()\n",
    "    xx = np.outer(x, x)\n",
    "    return xx\n",
    "\n",
    "gauss2d(3).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.2 \n",
    "\n",
    "Ορίζουμε παρακάτω 2 gabor φίλτρα με βάση τους τύπους της εκφώνησης."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gabor_filter_ev(r):  \n",
    "    t = np.linspace(-2*r, 2*r, int(4*r+1) )\n",
    "    v = 4/r\n",
    "    return np.cos(2*np.pi*v*t)*np.exp(-t**2 / 2 / (r**2))\n",
    "\n",
    "def gabor_filter_odd(r):  \n",
    "    t = np.linspace(-2*r, 2*r, int(4*r+1) )\n",
    "    v = 4/r\n",
    "    return np.sin(2*np.pi*v*t)*np.exp(-t**2 / 2 / (r**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 160, 20)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = read_video('./running/person01_running_d1_uncomp.avi', 20, 0)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(v):\n",
    "    for i in range(v.shape[-1]):\n",
    "        norm = np.linalg.norm(v[:,:,i], 1)\n",
    "        print(norm)\n",
    "        v[:,:,i] /= norm\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.719492367962139\n",
      "1.7266978856684143\n",
      "2.132085658895803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.12724526, 0.52244051, 0.39360759],\n",
       "        [0.19974574, 0.21661622, 0.15999441],\n",
       "        [0.57719252, 0.44987167, 0.32633029]],\n",
       "\n",
       "       [[0.16440793, 0.0918249 , 0.16344721],\n",
       "        [0.25677499, 0.10930957, 0.37070653],\n",
       "        [0.24500786, 0.53347513, 0.3200399 ]],\n",
       "\n",
       "       [[0.47455771, 0.20634593, 0.19527283],\n",
       "        [0.51682887, 0.53412983, 0.20766272],\n",
       "        [0.17779962, 0.01665321, 0.35362981]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=np.random.rand(3,3,3)\n",
    "normalize(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Εφαρμόζουμε τις συνελίξεις και υπολογίζουμε την Η ως την τετραγωνική ενέργεια εξόδου. Τέλος υπολογίζουμε πάλι τον Νχ4 πίνακα όπως και πριν."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gabor(img, sigma=2.5, r = 1.5, s=2, k=0.007, points=1000):\n",
    "    siz = int(2*np.ceil(3*s*sigma)+1)\n",
    "    smooth = convolve1d(img,cv2.getGaussianKernel(siz, s*sigma).flatten(), axis=0)\n",
    "    \n",
    "    smooth = convolve1d(smooth,cv2.getGaussianKernel(siz, s*sigma).flatten(), axis=1)\n",
    "    asdf=convolve1d(smooth, gabor_filter_ev(r), axis=-1)\n",
    "    \n",
    "    ev = convolve1d(smooth, gabor_filter_ev(r), axis=-1)\n",
    "    odd = convolve1d(smooth, gabor_filter_odd(r), axis=-1)\n",
    "    \n",
    "    H = ev**2+odd**2\n",
    "    \n",
    "    ss = np.full((points),sigma)\n",
    "    p = np.unravel_index(np.argsort(H, axis=None), H.shape)\n",
    "    \n",
    "    detect = np.zeros((4, points))\n",
    "    detect[0]=p[0][-points:]\n",
    "    detect[1]=p[1][-points:]\n",
    "    detect[2]=p[2][-points:]\n",
    "    detect[3]=ss\n",
    "    return detect.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Τρέχουμε εν συνεχεία τα πειράματα."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = read_video('./walking/person04_walking_d1_uncomp.avi', 200, 0)\n",
    "inp = Gabor(a, sigma=3, r=1.5, s=2, k=0.005, points=500)\n",
    "show_detection(a, inp, save_path=\"C:\\\\Users\\\\ΓΙΑΝΝΗΣ\\\\Desktop\\\\οραση\\\\lab2\\\\cv20_lab2_part2_material\\\\part2-videos\\\\Gabor_walking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = read_video('./boxing/person01_boxing_d2_uncomp.avi', 200, 0)\n",
    "inp = Gabor(a, sigma=3, r=1.5, s=2, k=0.005, points=500)\n",
    "show_detection(a, inp, save_path=\"C:\\\\Users\\\\ΓΙΑΝΝΗΣ\\\\Desktop\\\\οραση\\\\lab2\\\\cv20_lab2_part2_material\\\\part2-videos\\\\Gabor_boxing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = read_video('./running/person01_running_d1_uncomp.avi', 200, 0)\n",
    "inp = Gabor(a, sigma=3, r=1.5, s=2, k=0.005, points=500)\n",
    "show_detection(a, inp, save_path=\"C:\\\\Users\\\\ΓΙΑΝΝΗΣ\\\\Desktop\\\\οραση\\\\lab2\\\\cv20_lab2_part2_material\\\\part2-videos\\\\Gabor_running\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.656854249492381"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.array([[ 1, 2, 3], [-1, 1, 4]])\n",
    "np.linalg.norm(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Χωρο-χρονικοί Ιστογραφικοί Περιγραφητές"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2.1\n",
    "\n",
    "Προσθέτουμε τις συναρτήσεις του πρώτου μέρους για την υλοποιήση των HoG, HOFs. Δίνουμε έτσι ένα επιπλέον όρισμα το οποίο αν είναι True δίνει ΗΟF δηλαδή οπτικό πεδίο, αλλιώς δίνει κατευθυντικές παραγώγους HOGs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lk(I1, I2, rho, epsilon, isHOG, d_x0, d_y0):\n",
    "    x_0,y_0 = np.meshgrid(range(I1.shape[1]),range(I1.shape[0]))\n",
    "    In_1 = ndimage.map_coordinates(I1,np.array([np.ravel(y_0+d_y0), np.ravel(x_0+d_x0)]))\n",
    "    In_1 = In_1.reshape((I1.shape))\n",
    "    \n",
    "    dIn_1x, dIn_1y = np.gradient(In_1.reshape((I1.shape)))\n",
    "    #dIn_1x, dIn_1y = np.gradient(I1)\n",
    "    dIn_1x = dIn_1x.reshape((I1.shape))\n",
    "    dIn_1y = dIn_1y.reshape((I1.shape))\n",
    "    \n",
    "    if isHOG:\n",
    "        return dIn_1x, dIn_1y\n",
    "    \n",
    "    A1 = ndimage.map_coordinates(dIn_1x,np.array([np.ravel(y_0+d_y0), np.ravel(x_0+d_x0)]))\n",
    "    A2 = ndimage.map_coordinates(dIn_1y,np.array([np.ravel(y_0+d_y0), np.ravel(x_0+d_x0)]))\n",
    "    \n",
    "    A1 = A1.reshape((I1.shape))\n",
    "    A2 = A2.reshape((I1.shape))\n",
    "    \n",
    "    A = [A1, A2]\n",
    "    \n",
    "    E = I2 - In_1\n",
    "                    \n",
    "    G = cv2.getGaussianKernel(rho, (rho-1)/6) \n",
    "    \n",
    "    x = cv2.filter2D(A1**2, -1, G)+epsilon\n",
    "    y = cv2.filter2D(A1*A2, -1, G)\n",
    "    z = cv2.filter2D(A1*A2, -1, G)\n",
    "    w = cv2.filter2D(A2**2, -1, G)+epsilon\n",
    "    \n",
    "    a = cv2.filter2D(A1*E, -1, G)\n",
    "    b = cv2.filter2D(A2*E, -1, G)\n",
    "    \n",
    "    det = x*w - y*z\n",
    "    ux = (w*a - y*b) / det\n",
    "    uy = (b*x - z*a) / det\n",
    "    \n",
    "    dx = d_x0 + ux\n",
    "    dy = d_y0 + uy\n",
    "    \n",
    "    return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_d(I1, I2, rho, epsilon, isHOG, converge=10):\n",
    "    x_0,y_0 = np.meshgrid(range(I1.shape[1]),range(I1.shape[0]))\n",
    "    dx,dy = np.meshgrid(np.zeros(I1.shape[1]),np.zeros(I1.shape[0]))\n",
    "    #dx,dy = np.meshgrid(np.random.rand(I1.shape[1]),np.random.rand(I1.shape[0]))\n",
    "    #dx,dy = np.meshgrid(range(I1.shape[1]),range(I1.shape[0]))\n",
    "    #dx,dy = np.meshgrid(np.ones(I1.shape[1]),np.ones(I1.shape[0]))\n",
    "    for i in range(converge):\n",
    "        dx, dy = lk(I1, I2, rho, epsilon, isHOG, dx, dy)\n",
    "    \n",
    "    dx_r=cv2.resize(dx, None, fx=0.3, fy=0.3)\n",
    "    dy_r=cv2.resize(dy, None, fx=0.3, fy=0.3)\n",
    "    \n",
    "    x = range(dx_r.shape[1])\n",
    "    y = range(dx_r.shape[0])\n",
    "    '''\n",
    "    plt.quiver(x, y, -dx_r, -dy_r)\n",
    "    plt.gca().set_aspect('equal')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.quiver(x_0, y_0, -dx, -dy)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "    '''\n",
    "    return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 160, 200)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = read_video('./running/person01_running_d1_uncomp.avi', 200, 0)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(x):\n",
    "    if x>0:\n",
    "        return x\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv20_lab2_2_utils import orientation_histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.3\n",
    "\n",
    "Σε αυτό το σημείο υλοποιείται σύμφωνα με τις οδηγίες του πρώτου εργαστηρίου η orientation histogram. Κατά την εκτέλεση των πειραμάτων δοκιμάζεται και αυτή και η δοσμένη. Σχόλια επεξηγηματικά συνοδεύουν τον κώδικα στο παρακάτω cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10240,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx = np.random.rand(33,33)\n",
    "dy = np.random.rand(33,33)\n",
    "\n",
    "def orient_hist(dx, dy, nbins, h, w):\n",
    "    #Υπολογίζουμε τα προσανατολισμένα gradients από τα πεδία δχ, δυ\n",
    "    #Εφαρμόζουμε συνέλιξη προς τους δύο άξονες και βρίσκουμε τα ix, iy\n",
    "    g = [-1,0,1]\n",
    "    Ix = convolve1d(dx, g, axis=0)\n",
    "    Iy = convolve1d(dy, g, axis=1)\n",
    "    \n",
    "    #print('ix.shape', Ix.shape)\n",
    "    \n",
    "    #αυτό είναι το magnitude\n",
    "    M = np.sqrt(Ix**2+Iy**2)\n",
    "    #print('M.shape', M.shape)\n",
    "    \n",
    "    #αυτή είναι η γωνία από τα ιχ, ιυ. υπολογίζεται με numpy, αλλά επειδή επιστρέφει rad \n",
    "    #μετατρέπουμε σε μοίρες και κα΄νουμε τις αρνητικές τιμε΄ς θετικές με αντίστοιχες μοίρες που έχουν ίδια τιμή tan.\n",
    "    Angle = np.arctan2(Iy,Ix)/np.pi*180\n",
    "    Angle = np.where(Angle>0, Angle, Angle+180)\n",
    "    \n",
    "    #print('angle.shape',Angle.shape)\n",
    "    #Φτιάχνουμε παράθυρα μικρού μεγέθους εδώ 5χ5\n",
    "    r = 0.25\n",
    "    cell_size = 4\n",
    "    total_size = int(cell_size*2*r + cell_size)\n",
    "    diagrams = []\n",
    "    \n",
    "    #μοιράζουμε σε bins τις γωνίες.\n",
    "    wid = 180 / nbins\n",
    "    \n",
    "    #Για κάθε ένα από τα 33χ33 παράθυρα χωρίζουμε τις τιμές του magnitude σε nbins με βάση το width της γωνίας\n",
    "    #δηλαδή γωνία/wid μας δίνει σε ποιο bin του ιστογράμματος θα μπει η τιμή\n",
    "    #΄ύστερα συνενώνουμε όλα τα histograms.\n",
    "    \n",
    "    for i in range(0, h):         #,cell_size):\n",
    "        for j in range(0, w):             #,cell_size):\n",
    "            diag = np.zeros((nbins))\n",
    "            for k in range(i, min(i+total_size, h)):\n",
    "                for l in range(j, min(j+total_size, w)):\n",
    "                    \n",
    "                    index = int(np.floor(Angle[k,l]/wid))\n",
    "                    if index==nbins:\n",
    "                        index=nbins-1\n",
    "                    \n",
    "                    diag[index]+=M[k,l]\n",
    "            diagrams.append(diag)\n",
    "    \n",
    "    return np.concatenate( diagrams, axis=0 )\n",
    "\n",
    "\n",
    "h=orient_hist(dx, dy, 10, 32, 32)\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Η συνάρτηση αυτή γεμίζει με μηδενικά τα ορίσματα ι1, ι2 ώστε στην τελική να έχουν διαστάσεις he, wi. Είναι πολύ χρήσιμη ώστε να μην βγάζει error η παραπάνω orient_hist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(i1, i2, he, wi):\n",
    "    (xdim, ydim) = i1.shape\n",
    "    arr1 = np.zeros((he, wi))\n",
    "    arr2 = np.zeros((he, wi))\n",
    "    \n",
    "    if xdim<he and ydim<wi:\n",
    "        arr1[-xdim:, -ydim:]=i1\n",
    "        arr2[-xdim:, -ydim:]=i2\n",
    "    elif xdim<he and ydim==wi:\n",
    "        arr1[-xdim:, :]=i1\n",
    "        arr2[-xdim:, :]=i2\n",
    "    elif xdim==he and ydim<wi:\n",
    "        arr1[:, -ydim:]=i1\n",
    "        arr2[:, -ydim:]=i2\n",
    "\n",
    "    return arr1, arr2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2.2\n",
    "\n",
    "Η find_d μας δίνει είτε τις κατευθυντικές παραγώγους είτε τα οπτικά πεδία.\n",
    "Στη συνέχεια δίνουμε αυτά ως input στην orientation histogram είτε στην ατομική υλοποιήση. Για κάθε ένα από τα 500 ανιχνευθέντα σημεία καλούμε την orientation histogram και συνενώνουμε με τις προηγουμενες απεικονίσεις."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HOF_HOG(a, inp, isHOG, use_given, sigma=4):\n",
    "    s_window=4*sigma\n",
    "    width = 2*s_window+1\n",
    "    height = 2*s_window+1\n",
    "    total=[]\n",
    "    for i in range(inp.shape[0]):\n",
    "        starty = int(step(inp[i][0]-s_window))\n",
    "        startx = int(step(inp[i][1]-s_window))\n",
    "        I = a[:,:,int(inp[i][2])]\n",
    "        I = cv2.normalize(I, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "        I1 = I[starty:starty+height, startx:startx+width]\n",
    "        \n",
    "        I = a[:,:,int(inp[i][2])+1]\n",
    "        I = cv2.normalize(I, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "        I2 = I[starty:starty+height, startx:startx+width]\n",
    "        \n",
    "        if I1.shape!=(height, width):\n",
    "            #print('fixed')\n",
    "            I1, I2 = pad(I1, I2, height, width)\n",
    "        \n",
    "        dx, dy = find_d(I1, I2, 4, 0.05, isHOG, 5)\n",
    "        nbins=10\n",
    "        \n",
    "        \n",
    "        if use_given:\n",
    "            desc = orientation_histogram(dx,dy,nbins,np.array([height, width]))\n",
    "        else:\n",
    "            desc = orient_hist(dx,dy,nbins,height,width)\n",
    "        \n",
    "        total.append(desc)\n",
    "        \n",
    "    return np.vstack(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors = HOF_HOG(a, inp, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Όντως δίνει αποτέλεσμα της διάστασης που περιμέναμε."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 10890)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3: Κατασκευή Bag of Visual Words και χρήση Support Vector Machines για την ταξινόμηση δράσεων\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3.1\n",
    "Διαβάζουμε όλους τους τίτλους που υπάρχουν στο αρχείο training videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('traininng_videos.txt') as f:\n",
    "    content = f.readlines()\n",
    "train_videos = [x.strip() for x in content] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Στη συνέχεια διαβάζουμε τους τίτλους όλων των βίντεο και αφαιρούμε τους παραπάνω. Αυτό που προκύπτει είναι το test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person06_boxing_d1_uncomp.avi',\n",
       " 'person20_walking_d3_uncomp.avi',\n",
       " 'person10_running_d2_uncomp.avi',\n",
       " 'person25_running_d4_uncomp.avi',\n",
       " 'person15_boxing_d4_uncomp.avi',\n",
       " 'person07_boxing_d3_uncomp.avi',\n",
       " 'person24_running_d3_uncomp.avi',\n",
       " 'person11_walking_d1_uncomp.avi',\n",
       " 'person11_boxing_d2_uncomp.avi',\n",
       " 'person07_walking_d4_uncomp.avi',\n",
       " 'person08_walking_d2_uncomp.avi',\n",
       " 'person20_running_d1_uncomp.avi']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import listdir\n",
    "\n",
    "allvideos = listdir('boxing')+listdir('walking')+listdir('running')\n",
    "test_videos = list(set(allvideos)-set(train_videos))\n",
    "test_videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Για τα παραπάνω σύνολα εργαζόμαστε ως εξής:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Διαβάζουμε τα βίντεο, τα περνάμε από τον ανιχνευτή που θέλουμε, φτιάχνουμε έτσι τα represenations από το HOG/HOF και τα συνενώνουμε όλα."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Για την τελική μελέτη όλων των πιθανών μεθόδων, περιγραφητών και ανιχνευτών, θα εκτελέσουμε 8 πειράματα που αντιστοιχούν σε Gabor ή Harris, HOG ή HOF και στη δοσμένη υλοποίηση των histograms και μη."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "representations_gabor_hog_given = []\n",
    "representations_gabor_hog_mine = []\n",
    "representations_gabor_hof_given = []\n",
    "representations_gabor_hof_mine = []\n",
    "representations_harris_hog_given = []\n",
    "representations_harris_hog_mine = []\n",
    "representations_harris_hof_given = []\n",
    "representations_harris_hof_mine = []\n",
    "train_labels =[]\n",
    "for i in train_videos:\n",
    "    if 'running' in i:\n",
    "        file='running'\n",
    "    elif 'walking' in i:\n",
    "        file='walking'\n",
    "    else:\n",
    "        file='boxing'\n",
    "    train_labels.append(file)\n",
    "    a = read_video(os.path.join(file,i), 200, 0)\n",
    "    inp = HarrisStephens(a[:,:,:200], sigma=4, r=1.5, s=2, k=0.005, points=500)\n",
    "    descriptors1 = HOF_HOG(a, inp, True, True)\n",
    "    descriptors2 = HOF_HOG(a, inp, True, False)\n",
    "    descriptors3 = HOF_HOG(a, inp, False, True)\n",
    "    descriptors4 = HOF_HOG(a, inp, False, False)\n",
    "    inp = Gabor(a[:,:,:199], sigma=4, r=1.5, s=2, k=0.005, points=500)\n",
    "    descriptors5 = HOF_HOG(a, inp, True, True)\n",
    "    descriptors6 = HOF_HOG(a, inp, True, False)\n",
    "    descriptors7 = HOF_HOG(a, inp, False, True)\n",
    "    descriptors8 = HOF_HOG(a, inp, False, False)\n",
    "    \n",
    "    representations_harris_hog_given.append(descriptors1)\n",
    "    representations_harris_hog_mine.append(descriptors2)\n",
    "    representations_harris_hof_given.append(descriptors3)\n",
    "    representations_harris_hof_mine.append(descriptors4)\n",
    "    representations_gabor_hog_given.append(descriptors5)\n",
    "    representations_gabor_hog_mine.append(descriptors6)\n",
    "    representations_gabor_hof_given.append(descriptors7)\n",
    "    representations_gabor_hof_mine.append(descriptors8)\n",
    "    \n",
    "train_harris_hog_given = np.stack(representations_harris_hog_given)\n",
    "train_harris_hog_mine = np.stack(representations_harris_hog_mine)\n",
    "train_harris_hof_given = np.stack(representations_harris_hof_given)\n",
    "train_harris_hof_mine = np.stack(representations_harris_hof_mine)\n",
    "train_gabor_hog_given = np.stack(representations_gabor_hog_given)\n",
    "train_gabor_hog_mine = np.stack(representations_gabor_hog_mine)\n",
    "train_gabor_hof_given = np.stack(representations_gabor_hof_given)\n",
    "train_gabor_hof_mine = np.stack(representations_gabor_hof_mine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "representations_gabor_hog_given = []\n",
    "representations_gabor_hog_mine = []\n",
    "representations_gabor_hof_given = []\n",
    "representations_gabor_hof_mine = []\n",
    "representations_harris_hog_given = []\n",
    "representations_harris_hog_mine = []\n",
    "representations_harris_hof_given = []\n",
    "representations_harris_hof_mine = []\n",
    "test_labels=[]\n",
    "for i in test_videos:\n",
    "    if 'running' in i:\n",
    "        file='running'\n",
    "    elif 'walking' in i:\n",
    "        file='walking'\n",
    "    else:\n",
    "        file='boxing'\n",
    "    test_labels.append(file)\n",
    "    a = read_video(os.path.join(file,i), 201, 0)\n",
    "    inp = HarrisStephens(a[:,:,:200], sigma=4, r=1.5, s=2, k=0.005, points=500)\n",
    "    descriptors1 = HOF_HOG(a, inp, True, True)\n",
    "    descriptors2 = HOF_HOG(a, inp, True, False)\n",
    "    descriptors3 = HOF_HOG(a, inp, False, True)\n",
    "    descriptors4 = HOF_HOG(a, inp, False, False)\n",
    "    inp = Gabor(a[:,:,:200], sigma=4, r=1.5, s=2, k=0.005, points=500)\n",
    "    descriptors5 = HOF_HOG(a, inp, True, True)\n",
    "    descriptors6 = HOF_HOG(a, inp, True, False)\n",
    "    descriptors7 = HOF_HOG(a, inp, False, True)\n",
    "    descriptors8 = HOF_HOG(a, inp, False, False)\n",
    "    \n",
    "    representations_harris_hog_given.append(descriptors1)\n",
    "    representations_harris_hog_mine.append(descriptors2)\n",
    "    representations_harris_hof_given.append(descriptors3)\n",
    "    representations_harris_hof_mine.append(descriptors4)\n",
    "    representations_gabor_hog_given.append(descriptors5)\n",
    "    representations_gabor_hog_mine.append(descriptors6)\n",
    "    representations_gabor_hof_given.append(descriptors7)\n",
    "    representations_gabor_hof_mine.append(descriptors8)\n",
    "    \n",
    "test_harris_hog_given = np.stack(representations_harris_hog_given)\n",
    "test_harris_hog_mine = np.stack(representations_harris_hog_mine)\n",
    "test_harris_hof_given = np.stack(representations_harris_hof_given)\n",
    "test_harris_hof_mine = np.stack(representations_harris_hof_mine)\n",
    "test_gabor_hog_given = np.stack(representations_gabor_hog_given)\n",
    "test_gabor_hog_mine = np.stack(representations_gabor_hog_mine)\n",
    "test_gabor_hof_given = np.stack(representations_gabor_hof_given)\n",
    "test_gabor_hof_mine = np.stack(representations_gabor_hof_mine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Getting back the objects:\n",
    "with open('objs.pkl') as f:  # Python 3: open(..., 'rb')\n",
    "    test_harris_hog_given,\n",
    "            test_harris_hog_mine,\n",
    "            test_harris_hof_given,\n",
    "            test_harris_hof_mine,\n",
    "            test_gabor_hog_given,\n",
    "            test_gabor_hog_mine,\n",
    "            test_gabor_hof_given,\n",
    "            test_gabor_hof_mine, \n",
    "            train_harris_hog_given,\n",
    "            train_harris_hog_mine,\n",
    "            train_harris_hof_given,\n",
    "            train_harris_hof_mine,\n",
    "            train_gabor_hog_given,\n",
    "            train_gabor_hog_mine,\n",
    "            train_gabor_hof_given,\n",
    "            train_gabor_hof_mine = pickle.load(f)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.2\n",
    "\n",
    "Με χρήση της δοσμένης bag of words φέρνουμε όλες τις αναπαραστάσεις σε κοινή διάσταση."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv20_lab2_2_utils import bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "D=500\n",
    "bow_train, bow_test = bag_of_words(train_harris_hog_given, test_harris_hog_given, num_centers=D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.3\n",
    "Καλούμε στη συνέχεια τη συνάρτηση train και βλέπουμε τα αποτελέσματα."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv20_lab2_2_utils import svm_train_test\n",
    "\n",
    "accuracy, pred = svm_train_test(bow_train, train_labels, bow_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333 ['walking' 'boxing' 'running' 'running' 'running' 'running' 'running'\n",
      " 'running' 'running' 'running' 'boxing' 'running']\n"
     ]
    }
   ],
   "source": [
    "print(accuracy, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Για την τελική μελέτη όλων των πιθανών μεθόδων, περιγραφητών και ανιχνευτών, θα εκτελέσουμε 8 πειράματα που αντιστοιχούν σε \n",
    "Gabor ή Harris, HOG ή HOF και στη δοσμένη υλοποίηση των histograms και μη."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "harris_hog_given\n",
      "0.3333333333333333 ['walking' 'boxing' 'running' 'running' 'running' 'running' 'running'\n",
      " 'running' 'running' 'running' 'boxing' 'running']\n"
     ]
    }
   ],
   "source": [
    "bow_train, bow_test = bag_of_words(train_harris_hog_given, test_harris_hog_given, num_centers=D)\n",
    "accuracy, pred = svm_train_test(bow_train, train_labels, bow_test, test_labels)\n",
    "print('harris_hog_given')\n",
    "print(accuracy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "harris_hog_mine\n",
      "0.3333333333333333 ['walking' 'walking' 'boxing' 'boxing' 'boxing' 'boxing' 'running'\n",
      " 'running' 'boxing' 'boxing' 'walking' 'running']\n"
     ]
    }
   ],
   "source": [
    "bow_train, bow_test = bag_of_words(train_harris_hog_mine, test_harris_hog_mine, num_centers=D)\n",
    "accuracy, pred = svm_train_test(bow_train, train_labels, bow_test, test_labels)\n",
    "print('harris_hog_mine')\n",
    "print(accuracy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "harris_hof_given\n",
      "0.25 ['walking' 'boxing' 'running' 'boxing' 'running' 'running' 'running'\n",
      " 'running' 'running' 'running' 'boxing' 'running']\n"
     ]
    }
   ],
   "source": [
    "bow_train, bow_test = bag_of_words(train_harris_hof_given, test_harris_hof_given, num_centers=D)\n",
    "accuracy, pred = svm_train_test(bow_train, train_labels, bow_test, test_labels)\n",
    "print('harris_hof_given')\n",
    "print(accuracy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "harris_hof_mine\n",
      "0.4166666666666667 ['walking' 'boxing' 'boxing' 'boxing' 'walking' 'walking' 'walking'\n",
      " 'running' 'boxing' 'boxing' 'walking' 'walking']\n"
     ]
    }
   ],
   "source": [
    "bow_train, bow_test = bag_of_words(train_harris_hof_mine, test_harris_hof_mine, num_centers=D)\n",
    "accuracy, pred = svm_train_test(bow_train, train_labels, bow_test, test_labels)\n",
    "print('harris_hof_mine')\n",
    "print(accuracy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gabor_hog_given\n",
      "0.6666666666666666 ['running' 'boxing' 'running' 'running' 'boxing' 'running' 'running'\n",
      " 'running' 'boxing' 'running' 'boxing' 'boxing']\n"
     ]
    }
   ],
   "source": [
    "bow_train, bow_test = bag_of_words(train_gabor_hog_given, test_gabor_hog_given, num_centers=D)\n",
    "accuracy, pred = svm_train_test(bow_train, train_labels, bow_test, test_labels)\n",
    "print('gabor_hog_given')\n",
    "print(accuracy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gabor_hog_mine\n",
      "0.6666666666666666 ['running' 'boxing' 'running' 'running' 'boxing' 'running' 'running'\n",
      " 'running' 'running' 'running' 'walking' 'boxing']\n"
     ]
    }
   ],
   "source": [
    "bow_train, bow_test = bag_of_words(train_gabor_hog_mine, test_gabor_hog_mine, num_centers=D)\n",
    "accuracy, pred = svm_train_test(bow_train, train_labels, bow_test, test_labels)\n",
    "print('gabor_hog_mine')\n",
    "print(accuracy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gabor_hof_given\n",
      "0.6666666666666666 ['running' 'boxing' 'running' 'boxing' 'boxing' 'running' 'walking'\n",
      " 'running' 'boxing' 'running' 'running' 'boxing']\n"
     ]
    }
   ],
   "source": [
    "bow_train, bow_test = bag_of_words(train_gabor_hof_given, test_gabor_hof_given, num_centers=D)\n",
    "accuracy, pred = svm_train_test(bow_train, train_labels, bow_test, test_labels)\n",
    "print('gabor_hof_given')\n",
    "print(accuracy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gabor_hof_mine\n",
      "0.6666666666666666 ['running' 'boxing' 'walking' 'walking' 'walking' 'running' 'boxing'\n",
      " 'running' 'boxing' 'running' 'walking' 'boxing']\n"
     ]
    }
   ],
   "source": [
    "bow_train, bow_test = bag_of_words(train_gabor_hof_mine, test_gabor_hof_mine, num_centers=D)\n",
    "accuracy, pred = svm_train_test(bow_train, train_labels, bow_test, test_labels)\n",
    "print('gabor_hof_mine')\n",
    "print(accuracy, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Δοκιμάζουμε τέλος τα gabor φίλτρα με λιγότερα centroids και παρατηρούμε τα αποτελέσματα."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "D=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gabor_hog_given\n",
      "0.75 ['running' 'boxing' 'running' 'boxing' 'boxing' 'running' 'walking'\n",
      " 'running' 'boxing' 'running' 'walking' 'boxing']\n"
     ]
    }
   ],
   "source": [
    "bow_train, bow_test = bag_of_words(train_gabor_hog_given, test_gabor_hog_given, num_centers=D)\n",
    "accuracy, pred = svm_train_test(bow_train, train_labels, bow_test, test_labels)\n",
    "print('gabor_hog_given')\n",
    "print(accuracy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gabor_hof_given\n",
      "0.9166666666666666 ['running' 'boxing' 'walking' 'boxing' 'boxing' 'running' 'walking'\n",
      " 'running' 'boxing' 'walking' 'walking' 'boxing']\n"
     ]
    }
   ],
   "source": [
    "bow_train, bow_test = bag_of_words(train_gabor_hof_given, test_gabor_hof_given, num_centers=D)\n",
    "accuracy, pred = svm_train_test(bow_train, train_labels, bow_test, test_labels)\n",
    "print('gabor_hof_given')\n",
    "print(accuracy, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Παρατηρούμε ότι έχουμε πολυ καλύτερα αποτελέσματα. Για να δοκιμάσουμε την αποτελεσματικότητα των μοντέλων, μειώνουμε κι άλλο το D και εκτελούμε όλα τα Gabor μαζί με το καλύτερο από τα παραπάνω Harris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "harris_hof_mine\n",
      "0.5 ['running' 'boxing' 'running' 'running' 'boxing' 'boxing' 'boxing'\n",
      " 'running' 'boxing' 'running' 'boxing' 'walking']\n"
     ]
    }
   ],
   "source": [
    "bow_train, bow_test = bag_of_words(train_harris_hof_mine, test_harris_hof_mine, num_centers=D)\n",
    "accuracy, pred = svm_train_test(bow_train, train_labels, bow_test, test_labels)\n",
    "print('harris_hof_mine')\n",
    "print(accuracy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gabor_hog_given\n",
      "0.8333333333333334 ['running' 'boxing' 'running' 'boxing' 'boxing' 'running' 'walking'\n",
      " 'running' 'boxing' 'walking' 'walking' 'boxing']\n"
     ]
    }
   ],
   "source": [
    "bow_train, bow_test = bag_of_words(train_gabor_hog_given, test_gabor_hog_given, num_centers=D)\n",
    "accuracy, pred = svm_train_test(bow_train, train_labels, bow_test, test_labels)\n",
    "print('gabor_hog_given')\n",
    "print(accuracy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gabor_hog_mine\n",
      "0.6666666666666666 ['running' 'boxing' 'running' 'running' 'boxing' 'running' 'running'\n",
      " 'running' 'running' 'walking' 'walking' 'walking']\n"
     ]
    }
   ],
   "source": [
    "bow_train, bow_test = bag_of_words(train_gabor_hog_mine, test_gabor_hog_mine, num_centers=D)\n",
    "accuracy, pred = svm_train_test(bow_train, train_labels, bow_test, test_labels)\n",
    "print('gabor_hog_mine')\n",
    "print(accuracy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gabor_hof_given\n",
      "0.9166666666666666 ['running' 'boxing' 'walking' 'boxing' 'boxing' 'running' 'walking'\n",
      " 'running' 'boxing' 'walking' 'walking' 'boxing']\n"
     ]
    }
   ],
   "source": [
    "bow_train, bow_test = bag_of_words(train_gabor_hof_given, test_gabor_hof_given, num_centers=D)\n",
    "accuracy, pred = svm_train_test(bow_train, train_labels, bow_test, test_labels)\n",
    "print('gabor_hof_given')\n",
    "print(accuracy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gabor_hof_mine\n",
      "0.8333333333333334 ['running' 'boxing' 'walking' 'walking' 'boxing' 'running' 'boxing'\n",
      " 'running' 'boxing' 'walking' 'walking' 'boxing']\n"
     ]
    }
   ],
   "source": [
    "bow_train, bow_test = bag_of_words(train_gabor_hof_mine, test_gabor_hof_mine, num_centers=D)\n",
    "accuracy, pred = svm_train_test(bow_train, train_labels, bow_test, test_labels)\n",
    "print('gabor_hof_mine')\n",
    "print(accuracy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-118-1f98a3c744e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mtrain_gabor_hog_mine\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mtrain_gabor_hof_given\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             train_gabor_hof_mine], f)\n\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# obj0, obj1, obj2 are created here...\n",
    "\n",
    "# Saving the objects:\n",
    "with open('objs.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump([test_harris_hog_given,\n",
    "            test_harris_hog_mine,\n",
    "            test_harris_hof_given,\n",
    "            test_harris_hof_mine,\n",
    "            test_gabor_hog_given,\n",
    "            test_gabor_hog_mine,\n",
    "            test_gabor_hof_given,\n",
    "            test_gabor_hof_mine, \n",
    "            train_harris_hog_given,\n",
    "            train_harris_hog_mine,\n",
    "            train_harris_hof_given,\n",
    "            train_harris_hof_mine,\n",
    "            train_gabor_hog_given,\n",
    "            train_gabor_hog_mine,\n",
    "            train_gabor_hof_given,\n",
    "            train_gabor_hof_mine], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Επιλέγοντας τον καλύτερο συνδυασμό δοκιμάζουμε και άλλα splits των βίντεο"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'s': 1}\n"
     ]
    }
   ],
   "source": [
    "a = {'s':1}\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "allvideos = listdir('boxing')+listdir('walking')+listdir('running')\n",
    "\n",
    "print(len(allvideos))\n",
    "#test_videos = list(set(allvideos)-set(train_videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "train_videos = random.sample(allvideos, 36)\n",
    "test_videos = list(set(allvideos)-set(train_videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person06_running_d2_uncomp.avi',\n",
       " 'person25_walking_d4_uncomp.avi',\n",
       " 'person03_running_d3_uncomp.avi',\n",
       " 'person10_running_d2_uncomp.avi',\n",
       " 'person02_running_d2_uncomp.avi',\n",
       " 'person11_boxing_d2_uncomp.avi',\n",
       " 'person24_running_d3_uncomp.avi',\n",
       " 'person01_running_d1_uncomp.avi',\n",
       " 'person22_boxing_d2_uncomp.avi',\n",
       " 'person04_boxing_d1_uncomp.avi',\n",
       " 'person21_boxing_d1_uncomp.avi',\n",
       " 'person03_boxing_d4_uncomp.avi',\n",
       " 'person20_walking_d3_uncomp.avi',\n",
       " 'person02_boxing_d3_uncomp.avi',\n",
       " 'person18_walking_d4_uncomp.avi',\n",
       " 'person07_boxing_d3_uncomp.avi',\n",
       " 'person12_walking_d2_uncomp.avi',\n",
       " 'person05_boxing_d2_uncomp.avi',\n",
       " 'person16_walking_d2_uncomp.avi',\n",
       " 'person01_boxing_d2_uncomp.avi',\n",
       " 'person15_boxing_d4_uncomp.avi',\n",
       " 'person14_walking_d4_uncomp.avi',\n",
       " 'person05_running_d1_uncomp.avi',\n",
       " 'person24_boxing_d4_uncomp.avi',\n",
       " 'person07_running_d3_uncomp.avi',\n",
       " 'person06_boxing_d1_uncomp.avi',\n",
       " 'person11_walking_d1_uncomp.avi',\n",
       " 'person04_walking_d1_uncomp.avi',\n",
       " 'person17_walking_d3_uncomp.avi',\n",
       " 'person12_boxing_d3_uncomp.avi',\n",
       " 'person05_walking_d2_uncomp.avi',\n",
       " 'person13_walking_d3_uncomp.avi',\n",
       " 'person06_walking_d3_uncomp.avi',\n",
       " 'person21_running_d4_uncomp.avi',\n",
       " 'person20_running_d1_uncomp.avi',\n",
       " 'person09_boxing_d4_uncomp.avi']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'running': 10, 'walking': 12, 'boxing': 14}\n"
     ]
    }
   ],
   "source": [
    "representations_gabor_hof_given = []\n",
    "train_labels =[]\n",
    "balance = {'running':0, 'walking':0, 'boxing':0}\n",
    "for i in train_videos:\n",
    "    if 'running' in i:\n",
    "        file='running'\n",
    "    elif 'walking' in i:\n",
    "        file='walking'\n",
    "    else:\n",
    "        file='boxing'\n",
    "    balance[file]+=1\n",
    "    train_labels.append(file)\n",
    "    a = read_video(os.path.join(file,i), 200, 0)\n",
    "    inp = Gabor(a[:,:,:199], sigma=4, r=1.5, s=2, k=0.005, points=500)\n",
    "    descriptors7 = HOF_HOG(a, inp, False, True)\n",
    "    representations_gabor_hof_given.append(descriptors7)\n",
    "print(balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gabor_hof_given = np.stack(representations_gabor_hof_given)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'running': 6, 'walking': 4, 'boxing': 2}\n"
     ]
    }
   ],
   "source": [
    "representations_gabor_hof_given = []\n",
    "test_labels=[]\n",
    "balance = {'running':0, 'walking':0, 'boxing':0}\n",
    "for i in test_videos:\n",
    "    if 'running' in i:\n",
    "        file='running'\n",
    "    elif 'walking' in i:\n",
    "        file='walking'\n",
    "    else:\n",
    "        file='boxing'\n",
    "    balance[file]+=1\n",
    "    test_labels.append(file)\n",
    "    a = read_video(os.path.join(file,i), 201, 0)\n",
    "    inp = Gabor(a[:,:,:200], sigma=4, r=1.5, s=2, k=0.005, points=500)\n",
    "    descriptors7 = HOF_HOG(a, inp, False, True)\n",
    "    \n",
    "    representations_gabor_hof_given.append(descriptors7)\n",
    "    \n",
    "test_gabor_hof_given = np.stack(representations_gabor_hof_given)\n",
    "print(balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gabor_hof_given\n",
      "0.9166666666666666 ['walking' 'running' 'running' 'walking' 'running' 'walking' 'boxing'\n",
      " 'running' 'running' 'boxing' 'walking' 'walking']\n"
     ]
    }
   ],
   "source": [
    "from cv20_lab2_2_utils import bag_of_words, svm_train_test\n",
    "D=100\n",
    "bow_train, bow_test = bag_of_words(train_gabor_hof_given, test_gabor_hof_given, num_centers=D)\n",
    "accuracy, pred = svm_train_test(bow_train, train_labels, bow_test, test_labels)\n",
    "print('gabor_hof_given')\n",
    "print(accuracy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
